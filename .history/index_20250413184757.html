<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab Website - Home</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <link rel="icon" href="icons/favicon.ico">
</head>
<body>
    <header>
        <div class="logo">SPRAI: Security and Privacy Research of AI Systems Lab</div>
        <nav>
            <ul>
                <li><a href="#" class="active">Home</a></li>
                <li><a href="pages/research.html">Research</a></li>
                <li><a href="pages/people.html">People</a></li>
                <li><a href="pages/publications.html">Publications</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section class="carousel">
            <div class="carousel-track-container">
                <div class="carousel-track">
                    <div class="carousel-slide">
                        <img src="images/home/carousel-image-left.jpeg" alt="Carousel 2">
                        <div class="carousel-text">
                            <h1>Our Research</h1>
                            <p>Advancing robust AI: Federated learning, intrusion detection, and privacy-preserving techniques</p>
                        </div>
                    </div>
                    <div class="carousel-slide active">
                        <img src="images/home/carousel-image-center.jpeg" alt="Carousel 1">
                        <div class="carousel-text">
                            <h1>Welcome to SPRAI Lab</h1>
                            <p>Delve in to AI security research</p>
                        </div>
                    </div>
                    <div class="carousel-slide">
                        <img src="images/home/carousel-image-right.jpeg" alt="Carousel 3">
                        <div class="carousel-text">
                            <h1>Join Us</h1>
                            <p>Find Openings below to join the lab</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="carousel-nav">
                <span class="dot" data-slide="0"></span>
                <span class="dot active" data-slide="1"></span>
                <span class="dot" data-slide="2"></span>
            </div>
        </section>
        <div class="container">
            <section class="about">
                <h2>About</h2>
                <h3>SPRAI Lab focuses on the research of Trustworthy AI Systems</h3>
                <p>We dedicate to enhancing the security and privacy of AI systems, and applying advanced machine learning/deep learning methods to solve problems in security applications.
                    The research interests of SPRAI Lab include federated learning, network intrusion detection, adversarial machine learning, differential privacy, and large language models.
                    </p>
            </section>
            <section class="openings">
                <h2>Openings</h2>
                <div class="openings-grid">
                    <div class="opening">
                        <div class="opening-title">Multiple PhD Openings (with assistantship)</div>
                        <div class="opening-content">
                            I am looking for self-motivated students with research interests in any area of cybersecurity or the intersection of AI and security. If this opportunity interests you, reach out to me (ningw `at` usf.edu), providing your resume and any supplementary material that will help me gain insight into your academic background and research expertise.
                        </div>
                    </div>
                </div>
                <h2>Selected Papers</h2>
            </section>
            <section class="selected-papers">
                
                <div class="carousel-container">
                    <div class="sp-carousel-track">
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 1">
                            <p>Paper Title 1</p>
                        </div>
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 2">
                            <p>Paper Title 2</p>
                        </div>
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 3">
                            <p>Paper Title 3</p>
                        </div>
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 4">
                            <p>Paper Title 4</p>
                        </div>
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 5">
                            <p>Paper Title 5</p>
                        </div>
                        <div class="selected-paper">
                            <img src="/api/placeholder/300/200" alt="Selected Paper 6">
                            <p>Paper Title 6</p>
                        </div>
                    </div>
                </div>
            </section>
            <section class="news">
                <div class="news-container">
                    <div class="news-title">
                        <h2>News from<br>the Lab</h2>
                    </div>
                    <div class="news-content">
                        <ul>
                            <li><span class="news-date">Mar 2025</span> Our paper ‘Let the Noise Speak: Harnessing Noise for a Unified Defense Against Adversarial and Backdoor Attacks’ has been accepted by ESORICS 2025.</li>
                            <li><span class="news-date">Feb 2025</span> Our paper ‘Beyond Uniformity: Robust Backdoor Attacks on Deep Neural Networks with Trigger Selection’ has been accepted by PAKDD.</li>
                            <li><span class="news-date">Feb 2025</span> Our paper ‘FeCo: Boosting Intrusion Detection Capability in IoT Networks via Contrastive Learning’ has been accepted by TDSC.</li>
                            <li><span class="news-date">Jan 2025</span> Dr. Ning Wang will serve as a chair for MILCOM 2025 Track 3.</li>
                            <li><span class="news-date">Dec 2024</span> Our paper ‘FLARE: Defending Federated Learning against Model Poisoning Attacks via Latent Space Representations’ has been accepted by TDSC.</li>
                            <li><span class="news-date">Dec 2024</span> Our paper ‘Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction’ has been accepted by NDSS 2025.</li>
                            <li><span class="news-date">Aug 2024</span> Our paper ‘Adversarial Attacks on Federated Learning Revisited: a Client-Selection Perspective’ has been accepted to IEEE CNS 2024.</li>
                            <li><span class="news-date">Aug 2024</span> Our paper ‘Hermes: Boosting the Performance of Machine-Learning-based Intrusion Detection System through Geometric Feature Learning’ is accepted by ACM MobiHoc 2024.</li>
                            <li><span class="news-date">July 2024</span> Dr. Ning Wang will serve as a TPC member for AsiaCCS.</li>
                            <li><span class="news-date">May 2024</span> Dr. Ning Wang will serve as a TPC member for NDSS 2025 (fall cycle), IEEE MILCOM 2025, IEEE INFOCOM 2025 (also as Web Chair), and AACD co-located with ACM CCS 2024.</li>
                            <li><span class="news-date">Feb. 2024</span> Dr. Ning Wang will serve as a TPC member for WiseML 2024 in conjunction with ACM WiSec 2024.</li>
                            <li><span class="news-date">March 2024</span> [New Member] Sudharshan Balaji joined our group</li>
                            <li><span class="news-date">January 2024</span> [New Member] Zhengyuan Jiang Joined our group</li>
                            <li><span class="news-date">August 2023</span> [Selected Paper] our paper MINDFL: Mitigating the Impact of Imbalanced and Noisy-Labeled Data in Federated Learning with Quality and Fairness-Aware Client Selection’ is accepted by IEEE Military Communications Conference (MILCOM 2023)</li>
                            <li><span class="news-date">August 2023</span> [Start]  Dr. Ning Wang joined the CSE department and formed the SPRAI lab</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </main>
    <footer>
        <div class="footer-content">
            <div class="footer-column">
                <p>Security and Privacy Research of AI Systems Lab</p>
            </div>
            <div class="footer-column">
                <p>Research</p>
                <p>Publications</p>
                <p>People</p>
            </div>
            <div class="footer-column">
                <p>Courses</p>
                <p>Resources</p>
                <p>News</p>
            </div>
            <div class="footer-column">
                <p>Contact</p>
                <p>About</p>
                <p>Join Us</p>
            </div>
        </div>
    </footer>
    <script src="scripts/carousel.js"></script>
    <script src="scripts/selected-papers-carousel.js"></script>
</body>
</html>
